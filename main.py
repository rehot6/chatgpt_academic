import os; os.environ['no_proxy'] = '*' # é¿å…ä»£ç†ç½‘ç»œäº§ç”Ÿæ„å¤–æ±¡æŸ“
import gradio as gr
from request_llm.bridge_chatgpt import predict
from toolbox import format_io, find_free_port, on_file_uploaded, on_report_generated, get_conf, ArgsGeneralWrapper, DummyWith

API_KEY = os.environ.get('MY_API_KEY')
# å»ºè®®æ‚¨å¤åˆ¶ä¸€ä¸ªconfig_private.pyæ”¾è‡ªå·±çš„ç§˜å¯†, å¦‚APIå’Œä»£ç†ç½‘å€, é¿å…ä¸å°å¿ƒä¼ githubè¢«åˆ«äººçœ‹åˆ°
proxies, WEB_PORT, LLM_MODEL, CONCURRENT_COUNT, AUTHENTICATION, CHATBOT_HEIGHT, LAYOUT= \
    get_conf('proxies', 'WEB_PORT', 'LLM_MODEL', 'CONCURRENT_COUNT', 'AUTHENTICATION', 'CHATBOT_HEIGHT', 'LAYOUT')

# å¦‚æœWEB_PORTæ˜¯-1, åˆ™éšæœºé€‰å–WEBç«¯å£
PORT = find_free_port() if WEB_PORT <= 0 else WEB_PORT
if not AUTHENTICATION: AUTHENTICATION = None

from check_proxy import get_current_version
initial_prompt = "Serve me as a writing and programming assistant."
title_html = f"<h1 align=\"center\">ChatGPT å­¦æœ¯ä¼˜åŒ– {get_current_version()}</h1>"
description =  """ä»£ç å¼€æºå’Œæ›´æ–°[åœ°å€ğŸš€](https://github.com/binary-husky/chatgpt_academic)ï¼Œæ„Ÿè°¢çƒ­æƒ…çš„[å¼€å‘è€…ä»¬â¤ï¸](https://github.com/binary-husky/chatgpt_academic/graphs/contributors)"""

# é—®è¯¢è®°å½•, python ç‰ˆæœ¬å»ºè®®3.9+ï¼ˆè¶Šæ–°è¶Šå¥½ï¼‰
import logging
os.makedirs("gpt_log", exist_ok=True)
try:logging.basicConfig(filename="gpt_log/chat_secrets.log", level=logging.INFO, encoding="utf-8")
except:logging.basicConfig(filename="gpt_log/chat_secrets.log", level=logging.INFO)
print("æ‰€æœ‰é—®è¯¢è®°å½•å°†è‡ªåŠ¨ä¿å­˜åœ¨æœ¬åœ°ç›®å½•./gpt_log/chat_secrets.log, è¯·æ³¨æ„è‡ªæˆ‘éšç§ä¿æŠ¤å“¦ï¼")

# ä¸€äº›æ™®é€šåŠŸèƒ½æ¨¡å—
from core_functional import get_core_functions
functional = get_core_functions()

# é«˜çº§å‡½æ•°æ’ä»¶
from crazy_functional import get_crazy_functions
crazy_fns = get_crazy_functions()

# å¤„ç†markdownæ–‡æœ¬æ ¼å¼çš„è½¬å˜
gr.Chatbot.postprocess = format_io

# åšä¸€äº›å¤–è§‚è‰²å½©ä¸Šçš„è°ƒæ•´
from theme import adjust_theme, advanced_css
set_theme = adjust_theme()

# ä»£ç†ä¸è‡ªåŠ¨æ›´æ–°
from check_proxy import check_proxy, auto_update
# proxy_info = check_proxy(proxies)
proxy_info =  f"æ— ä»£ç†"


gr_L1 = lambda: gr.Row().style()
gr_L2 = lambda scale: gr.Column(scale=scale)
if LAYOUT == "TOP-DOWN": 
    gr_L1 = lambda: DummyWith()
    gr_L2 = lambda scale: gr.Row()
    CHATBOT_HEIGHT /= 2

cancel_handles = []
with gr.Blocks(title="ChatGPT å­¦æœ¯ä¼˜åŒ–", theme=set_theme, analytics_enabled=False, css=advanced_css) as demo:
    gr.HTML(title_html)
    cookies = gr.State({'api_key': API_KEY, 'llm_model': LLM_MODEL})

def follow_file(filename):
    import time
    # è·å–æ–‡ä»¶å¤§å°å’Œæœ€åä¿®æ”¹æ—¶é—´
    file_size = os.path.getsize(filename)
    last_modified = os.path.getmtime(filename)
    # å¼€å§‹è¿½è¸ªæ–‡ä»¶
    with open(filename, 'r') as f:
        while True:
            # å¦‚æœæ–‡ä»¶å·²ç»è¢«æˆªæ–­ï¼Œåˆ™é‡æ–°å¼€å§‹è¿½è¸ª
            if os.path.getsize(filename) < file_size:
                file_size = 0
                f.seek(0)

            # è¯»å–æ–°æ·»åŠ åˆ°æ–‡ä»¶ä¸­çš„å†…å®¹
            new_data = f.read()

            # å¦‚æœæ–‡ä»¶å‘ç”Ÿäº†å˜åŒ–ï¼Œåˆ™è¾“å‡ºç›¸åº”çš„ä¿¡æ¯
            if new_data:
                file_size += len(new_data)
                last_modified = os.path.getmtime(filename)
                print(f"File {filename} has been modified at {last_modified}:")
                print(new_data)

            # æš‚åœä¸€æ®µæ—¶é—´å†ç»§ç»­è¿½è¸ªæ–‡ä»¶
            time.sleep(1)
# gradioçš„inbrowserè§¦å‘ä¸å¤ªç¨³å®šï¼Œå›æ»šä»£ç åˆ°åŸå§‹çš„æµè§ˆå™¨æ‰“å¼€å‡½æ•°
def auto_opentab_delay():
    import threading, webbrowser, time
    print(f"å¦‚æœæµè§ˆå™¨æ²¡æœ‰è‡ªåŠ¨æ‰“å¼€ï¼Œè¯·å¤åˆ¶å¹¶è½¬åˆ°ä»¥ä¸‹URLï¼š")
    print(f"\tï¼ˆäº®è‰²ä¸»é¢˜ï¼‰: http://localhost:{PORT}")
    print(f"\tï¼ˆæš—è‰²ä¸»é¢˜ï¼‰: http://localhost:{PORT}/?__dark-theme=true")
    def open(): 
        time.sleep(2)       # æ‰“å¼€æµè§ˆå™¨
        webbrowser.open_new_tab(f"http://localhost:{PORT}/?__dark-theme=true")
    threading.Thread(target=open, name="open-browser", daemon=True).start()
    threading.Thread(target=auto_update, name="self-upgrade", daemon=True).start()
    threading.Thread(target=follow_file, args=("gpt_log/chat_secrets.log",), name="log", daemon=True).start()
# auto_opentab_delay()
demo.queue(concurrency_count=CONCURRENT_COUNT).launch(server_name="0.0.0.0", server_port=PORT, auth=AUTHENTICATION,debug=True)
